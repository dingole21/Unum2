Definitions:
ℝᵖ - projective reals.
ℝᵖ/L - projective reals represented by a Type2 Unum Lattice L.  The elements
are intervals, which will be denoted as x̅.  An element of may also be an exact
value or an ulp value, which will be denoted as ẋ.

O:(ℝᵖ/L)ⁿ → ℝᵖ/L is an *implementation* of an operation o:(ℝᵖ)ⁿ → ℝᵖ.  The
implementation must have the property o(x) ∈ O(ẋ), where ẋ is the unique ulp
or exact value in ℝᵖ/L containing x.

O:(ℝᵖ/L)ⁿ → ℝᵖ/L has "minimal bounding error" if
  ∀ (ẏ ⊆ O(<x̅ᵢ…>)), ∃ <xᵢ…> ∈ <x̅ᵢ…> | o(<xᵢ…>) ∈ ẏ

o:(ℝᵖ)ⁿ → ℝᵖ is "partially monotonic" if all partial applications yielding a
  single valued function are monotonic.

o:(ℝᵖ)ⁿ → ℝᵖ is "totally monotonic" if it is partially monotonic, and all single
  valued, partial applications keeping the same index free have the same
  monotonicity.

Lookup table lemma:  if o(<ẋᵢ…>) is partially monotonic and an ulp or an exact
  value for all exact vectors <ẋᵢ…>, there ∃ a trivially constructible O with
  minimal bounding error.

Proof, by induction over set construction.
  Base case:  <ẋᵢ…> - exact vector.  Then let ẏ = O(<ẋᵢ…>).  Since the only
  nonempty subset of ẏ is ẏ itself, the minimal bounding criterion is fulfilled
  by lookup table.
  Inductive case 1:  <ẋᵢ…> - exact except for n + 1 dimensions, which are ulps.
    Assume the minimal bounding criterion applies when <ẋᵢ…> is exact over n ulps.
    WOLOG, let ẋ₁ be a an ulp, and f(z) = O(<x₁ₗ, ẋ₂…>), defined by lookup, is
    monotonic positive, by the definition of partially monotonic.  Examine the
    bounding values x₁ₗ and x₁ₕ, where x₁ₗ is glb(ẋ₁) and x₁ₕ is lub(ẋ₁).  By
    definition, x₁ₗ < x₁ₕ; and we'll define provisional variables:
    ẏₗₚ = O(<x₁ₗ, ẋ₂…>) < O(<x₁ₕ, ẋ₂…>) = ẏₕₚ.  If ẏₗₚ is exact, let ẏₗ be the
    ulp above ẏₗₚ, otherwise ẏₗ := ẏₗₚ; construct ẏₗ symmetrically.

    Pick any x > ẋ₁ₗ, by the monotonicity of f, f(x) > f(ẋ₁ₗ) = ẏₗₚ.  Similarly,
    for any x < ẋ₁ₕ, f(x) < f(ẋ₁ₕ) = ẏₕₚ.  Therefore, the construction
    f(x) = ẏₗ…ẏₕ corresponds to a implementation O of o over n+1 ulps.  It
    remains to show that O is minimally bounded over n+1 ulps.

    Examine the external ulp ẏₗ.  Using the value yₗₕ which is lub(ẏₗ), pick
    ϵ = (yₗₕ - f(x₁ₗ))/2.  By continuity,
      ∃ δ | f(x₁ₗ) < f(x₁ₗ + δ) < f(x₁ₗ) + ϵ < yₗₕ
      therefore f(x₁ₗ + δ) = ẏₗ ⊆ O(<x₁ₗ, ẋ₂…>).  Repeat the process with ẏₕ.
      If some ẏ ⊆ ẏₗ…ẏₕ -exact, by the intermediate value theorem, we know that
      for some vector <xᵢ…> in <ẋᵢ…>, o(<xᵢ…>) = ẏ.  For a non-edge ulp ẏₘ, we
      may repeat the process as the edge ulp, using ϵ = (lub(ẏₘ) - glb(ẏₘ))/2,
      and the intermediate value theorem result.

  Inductive case 2:  <x̅ᵢ…> - SORNs of size (m tiles) except for n + 1 dimensions,
    which are SORNs of size (m + 1 tiles).  WOLOG, let x̅ᵢ have size
    (m + 1 tiles).  Construct two regions, the first by subtracting the greatest
    tile out of x̅ᵢ.  By induction, O over both regions satisfy minimal
    boundedness.  Therefore, the strict union of both images satisfies minimal
    boundedness.

Corollary:  Operations +, -, *, /, implemented using lookup tables, have minimal
  bounding error.

Observation:  The composition of two operations which have minimal bounding error
  does not necessarily have minimal bounding error.  E.g.  FMA(a, b, c) := (a * b) + c
  generally does not satisfy this property.  Examine the simple 4-bit PTile with
  a = 2, b = 2, c = -2.  (a * b) yields the interval (2 ∞), and adding -2 yields
  a final result of (0 ∞), which contains the correct solution [2] but also
  includes severals tiles that do not: (0 1/2), [1/2], (1/2 1), [1], (1 2),
  (2 ∞).

"Repairing" a n-ary composed operation to have minimal bounding error is
desirable.  One possibility is to naively iterate through all combinations of
exact values and assign problematic values to a hash table, which can then be
compared to a lookup prior to calculation.

For the specific case of FMA, one potential problem is overflow, which can be
easily "repaired" by holding the values in a temporary state beyond the upper
limit of the lattice.  In the case where epoch calculations are performed,
explicitly composing the multiply and add code, passing the epoch information
between the two.  In the case of 4-bit and 5-bit unums, this strategy is
sufficient to result in an FMA with minimal bounding error.  Most well-defined
lattices will have this property.

A third strategy is to rewrite the equation.  In the case of FMA, performing
three calculations is possible:  (a * b) + c is equivalent to (a + c/b) * b and
(b + c/a) * a.  Because lattice-based floating point lookup operations are fast,
performing these operations (possibly in parallel), followed by a set
intersection operation.  This strategy is sufficient to result in an FMA with
minimal bounding error for 4-bit and 5-bit unums.  When generating lattice
tables, it is relatively easy to identify which lattice inputs are repaired
by rewrite.

Combining all three strategies is likely to result in efficient,
high-performance FMA (and other n-ary) operations, and for software
implementations of this floating point, these cases can be identified at
compile-time with minimal effort; for hardware implementations of lattices,
all strategies are relatively easy as well.
